### 缓存在CPU架构的工作原理
CPU中缓存的最小化单位是缓存行（大小为64字节）
因此，当CPU从内存中读取变量时，它将读取该变量附近的所有变量。顺便一提，CPU从内存批量读取变量的主要原因是基于空间局部性理论：当CPU访问一个变量时，它可能很快就会读取它旁边的变量，术语一点就是，计算机程序倾向于引用临近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。
怎么理解呢
```
func sumArrayRows(m  int , a []int) int {
	i , sum := 0  , 0
	for i = 0; i < m; i++ {
		sum += a[i]
	}
	return sum
}
```

就像上面的代码，在双层嵌套循环中，函数按照优先顺序读取数组元素，具备良好的空间局限性。

回到原本的问题，那么对于一个cache line ，可能会出现一个问题，如果一个变量存在于不同CPU核心中的两个缓存行中，当其中一个core1更新某个变量A时，另外一个core2读取相邻的变量B，即使B未被修改，core2的缓存也会被设为未命中，所以core2会从内存中重新加载缓存行中的所有变量，这也就是cache的false sharing：一个CPU核更新变量会强制其他CPU核更新缓存，而我们知道从缓存读取CPU的变量比从内存中读取变量快得多。因此，虽然该变量一直存在于多核中，但这会显著影响性能。

业界解决该问题的常用方法是缓存填充：在变量之间填充一些无意义的变量，使一个变量单独占用CPU核的缓存行，因此其他核更新时，其他变量不会使该核从内存中重新加载变量。

### 代码说明

代码对false sharing的情况做了轻量化的模拟，在benchmark下模拟已经显示出一个很大的提高

运行结果如下：
```
goos: darwin
goarch: amd64
pkg: test-local/falseSharing
BenchmarkNoPad-12       1000000000               0.0585 ns/op
BenchmarkPad-12         1000000000               0.0262 ns/op
PASS
ok      test-local/falseSharing 1.091s

```

### 最后做一点解释：

1. cache line的大小跟CPU有关，不同CPU会导致填充大小有差异；
2. 填充多也意味着内存资源的消耗，基准测试是必要的；